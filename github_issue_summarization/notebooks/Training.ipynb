{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "drwxr-xr-x 2 root root 4096 Apr 12 10:26 .\n",
      "drwxr-xr-x 1 root root 4096 Apr 28 00:11 ..\n"
     ]
    }
   ],
   "source": [
    "# Ensure that the github-issues-data volume is mounted in /mnt\n",
    "!ls -la /mnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATA_DIR=/home/jovyan/work/github-issues-data\n"
     ]
    }
   ],
   "source": [
    "# Set path for data dir\n",
    "%env DATA_DIR=/home/jovyan/work/github-issues-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Download the github-issues.zip training data to /mnt/github-issues-data\n",
    "if False:\n",
    "    !wget --directory-prefix=${DATA_DIR} https://storage.googleapis.com/kubeflow-examples/github-issue-summarization-data/github-issues.zip\n",
    "\n",
    "    # Unzip the file into /mnt/github-issues-data directory\n",
    "    !unzip ${DATA_DIR}/github-issues.zip -d ${DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a symlink from <current_directory>/github-issues-data to /mnt/github-issues-data\n",
    "!ln -sf ${DATA_DIR} github-issues-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan joyvan 2.7G Jan 17 21:28 github-issues-data/github_issues.csv\n"
     ]
    }
   ],
   "source": [
    "# Make sure that the github-issues-data symlink is created\n",
    "!ls -lh github-issues-data/github_issues.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test set and preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1,800 rows 3 columns\n",
      "Test: 200 rows 3 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3219968</th>\n",
       "      <td>\"https://github.com/colebemis/feather/issues/70\"</td>\n",
       "      <td>icon request: bath</td>\n",
       "      <td>hi, thanks for the great set of icons! how about some icons for describing rooms within a house icon name: bath use case: many real estate agents make use of such icons when advertising properties. i've included an example below. ! image https://cloud.githubusercontent.com/assets/3124180/26781539/fe82e570-49e6-11e7-8495-309cffcc13b1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098599</th>\n",
       "      <td>\"https://github.com/7696122/evil-terminal-cursor-changer/issues/18\"</td>\n",
       "      <td>in iterm2 i get an error void-variable seq but a subsequent call makes it work</td>\n",
       "      <td>the first time i call evil-terminal-cursor-changer-activate i get an error stating void-variable seq . if i invoke it again it works and the cursor does change according to state. i have tried emacs --debug-init but it doesn't show any stack trace so i am not sure what the next step is? the way i am invoking it is: unless display-graphic-p use-package evil-terminal-cursor-changer :ensure t :init setq evil-motion-state-cursor 'box ; █ setq evil-visual-state-cursor 'box ; █ setq evil-normal-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4217192</th>\n",
       "      <td>\"https://github.com/turnkeylinux/tracker/issues/869\"</td>\n",
       "      <td>django v14.2 appears broken unless you browse to domain set in firstboot</td>\n",
       "      <td>for v14.2 django requires a domain name to server from. however, most of our documentation suggests that you can access machines via ip address. so for the next release the django appliance should auto redirect to the url that was set...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   issue_url  \\\n",
       "3219968                     \"https://github.com/colebemis/feather/issues/70\"   \n",
       "2098599  \"https://github.com/7696122/evil-terminal-cursor-changer/issues/18\"   \n",
       "4217192                 \"https://github.com/turnkeylinux/tracker/issues/869\"   \n",
       "\n",
       "                                                                            issue_title  \\\n",
       "3219968                                                              icon request: bath   \n",
       "2098599  in iterm2 i get an error void-variable seq but a subsequent call makes it work   \n",
       "4217192        django v14.2 appears broken unless you browse to domain set in firstboot   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        body  \n",
       "3219968                                                                                                                                                                   hi, thanks for the great set of icons! how about some icons for describing rooms within a house icon name: bath use case: many real estate agents make use of such icons when advertising properties. i've included an example below. ! image https://cloud.githubusercontent.com/assets/3124180/26781539/fe82e570-49e6-11e7-8495-309cffcc13b1.png  \n",
       "2098599  the first time i call evil-terminal-cursor-changer-activate i get an error stating void-variable seq . if i invoke it again it works and the cursor does change according to state. i have tried emacs --debug-init but it doesn't show any stack trace so i am not sure what the next step is? the way i am invoking it is: unless display-graphic-p use-package evil-terminal-cursor-changer :ensure t :init setq evil-motion-state-cursor 'box ; █ setq evil-visual-state-cursor 'box ; █ setq evil-normal-st...  \n",
       "4217192                                                                                                                                                                                                                                                                        for v14.2 django requires a domain name to server from. however, most of our documentation suggests that you can access machines via ip address. so for the next release the django appliance should auto redirect to the url that was set...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file='github-issues-data/github_issues.csv'\n",
    "\n",
    "# read in data sample 2000 rows (for speed of tutorial)\n",
    "# Set this to False to train on the entire dataset\n",
    "use_sample_data=True\n",
    "\n",
    "if use_sample_data:\n",
    "    training_data_size=2000\n",
    "    traindf, testdf = train_test_split(pd.read_csv(data_file).sample(n=training_data_size), \n",
    "                                   test_size=.10)\n",
    "else:\n",
    "    traindf, testdf = train_test_split(pd.read_csv(data_file),test_size=.10)\n",
    "\n",
    "\n",
    "#print out stats about shape of data\n",
    "print(f'Train: {traindf.shape[0]:,} rows {traindf.shape[1]:,} columns')\n",
    "print(f'Test: {testdf.shape[0]:,} rows {testdf.shape[1]:,} columns')\n",
    "\n",
    "# preview data\n",
    "traindf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to lists in preparation for modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hi, thanks for the great set of icons! how about some icons for describing rooms within a house icon name: bath use case: many real estate agents make use of such icons when advertising properties. i've included an example below. ! image https://cloud.githubusercontent.com/assets/3124180/26781539/fe82e570-49e6-11e7-8495-309cffcc13b1.png\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_body_raw = traindf.body.tolist()\n",
    "train_title_raw = traindf.issue_title.tolist()\n",
    "#preview output of first element\n",
    "train_body_raw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process Data For Deep Learning\n",
    "\n",
    "See [this repo](https://github.com/hamelsmu/ktext) for documentation on the ktext package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from ktext.preprocess import processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:....tokenizing data\n",
      "WARNING:root:(1/2) done. 1 sec\n",
      "WARNING:root:....building corpus\n",
      "WARNING:root:(2/2) done. 0 sec\n",
      "WARNING:root:Finished parsing 1,800 documents.\n",
      "WARNING:root:...fit is finished, beginning transform\n",
      "WARNING:root:...padding data\n",
      "WARNING:root:done. 0 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 260 ms, sys: 525 ms, total: 785 ms\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Clean, tokenize, and apply padding / truncating such that each document length = 70\n",
    "#  also, retain only the top 8,000 words in the vocabulary and set the remaining words\n",
    "#  to 1 which will become common index for rare words \n",
    "body_pp = processor(keep_n=8000, padding_maxlen=70)\n",
    "train_body_vecs = body_pp.fit_transform(train_body_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at one example of processed issue bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original string:\n",
      " hi, thanks for the great set of icons! how about some icons for describing rooms within a house icon name: bath use case: many real estate agents make use of such icons when advertising properties. i've included an example below. ! image https://cloud.githubusercontent.com/assets/3124180/26781539/fe82e570-49e6-11e7-8495-309cffcc13b1.png \n",
      "\n",
      "after pre-processing:\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0  160\n",
      "  128   14    3  418   85   10  780   73  139   67  780   14 1693 2409\n",
      "  488    5 3386  587   61 6572   39  269  396  781 4406 6573   77   39\n",
      "   10  298  780   29 6574  654    6  242  953   31   98  291  113   11] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\noriginal string:\\n', train_body_raw[0], '\\n')\n",
    "print('after pre-processing:\\n', train_body_vecs[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:....tokenizing data\n",
      "WARNING:root:(1/2) done. 0 sec\n",
      "WARNING:root:....building corpus\n",
      "WARNING:root:(2/2) done. 0 sec\n",
      "WARNING:root:Finished parsing 1,800 documents.\n",
      "WARNING:root:...fit is finished, beginning transform\n",
      "WARNING:root:...padding data\n",
      "WARNING:root:done. 0 sec\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a text processor for the titles, with some different parameters\n",
    "#  append_indicators = True appends the tokens '_start_' and '_end_' to each\n",
    "#                      document\n",
    "#  padding = 'post' means that zero padding is appended to the end of the \n",
    "#             of the document (as opposed to the default which is 'pre')\n",
    "title_pp = processor(append_indicators=True, keep_n=4500, \n",
    "                     padding_maxlen=12, padding ='post')\n",
    "\n",
    "# process the title data\n",
    "train_title_vecs = title_pp.fit_transform(train_title_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at one example of processed issue titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original string:\n",
      " icon request: bath\n",
      "after pre-processing:\n",
      " [   2  185   56 1477    3    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print('\\noriginal string:\\n', train_title_raw[0])\n",
    "print('after pre-processing:\\n', train_title_vecs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialize all of this to disk for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill as dpickle\n",
    "import numpy as np\n",
    "\n",
    "# Save the preprocessor\n",
    "with open('body_pp.dpkl', 'wb') as f:\n",
    "    dpickle.dump(body_pp, f)\n",
    "\n",
    "with open('title_pp.dpkl', 'wb') as f:\n",
    "    dpickle.dump(title_pp, f)\n",
    "\n",
    "# Save the processed data\n",
    "np.save('train_title_vecs.npy', train_title_vecs)\n",
    "np.save('train_body_vecs.npy', train_body_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data from disk into variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from seq2seq_utils import load_decoder_inputs, load_encoder_inputs, load_text_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder input: (1800, 70)\n",
      "Shape of decoder input: (1800, 11)\n",
      "Shape of decoder target: (1800, 11)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data, doc_length = load_encoder_inputs('train_body_vecs.npy')\n",
    "decoder_input_data, decoder_target_data = load_decoder_inputs('train_title_vecs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary for body_pp.dpkl: 8002\n",
      "Size of vocabulary for title_pp.dpkl: 4178\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens, body_pp = load_text_processor('body_pp.dpkl')\n",
    "num_decoder_tokens, title_pp = load_text_processor('title_pp.dpkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional, BatchNormalization\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#arbitrarly set latent dimension for embedding and hidden units\n",
    "latent_dim = 300\n",
    "\n",
    "##### Define Model Architecture ######\n",
    "\n",
    "########################\n",
    "#### Encoder Model ####\n",
    "encoder_inputs = Input(shape=(doc_length,), name='Encoder-Input')\n",
    "\n",
    "# Word embeding for encoder (ex: Issue Body)\n",
    "x = Embedding(num_encoder_tokens, latent_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\n",
    "x = BatchNormalization(name='Encoder-Batchnorm-1')(x)\n",
    "\n",
    "# Intermediate GRU layer (optional)\n",
    "#x = GRU(latent_dim, name='Encoder-Intermediate-GRU', return_sequences=True)(x)\n",
    "#x = BatchNormalization(name='Encoder-Batchnorm-2')(x)\n",
    "\n",
    "# We do not need the `encoder_output` just the hidden state.\n",
    "_, state_h = GRU(latent_dim, return_state=True, name='Encoder-Last-GRU')(x)\n",
    "\n",
    "# Encapsulate the encoder as a separate entity so we can just \n",
    "#  encode without decoding if we want to.\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=state_h, name='Encoder-Model')\n",
    "\n",
    "seq2seq_encoder_out = encoder_model(encoder_inputs)\n",
    "\n",
    "########################\n",
    "#### Decoder Model ####\n",
    "decoder_inputs = Input(shape=(None,), name='Decoder-Input')  # for teacher forcing\n",
    "\n",
    "# Word Embedding For Decoder (ex: Issue Titles)\n",
    "dec_emb = Embedding(num_decoder_tokens, latent_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\n",
    "dec_bn = BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n",
    "\n",
    "# Set up the decoder, using `decoder_state_input` as initial state.\n",
    "decoder_gru = GRU(latent_dim, return_state=True, return_sequences=True, name='Decoder-GRU')\n",
    "decoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out)\n",
    "x = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n",
    "\n",
    "# Dense layer for prediction\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Final-Output-Dense')\n",
    "decoder_outputs = decoder_dense(x)\n",
    "\n",
    "########################\n",
    "#### Seq2Seq Model ####\n",
    "\n",
    "#seq2seq_decoder_out = decoder_model([decoder_inputs, seq2seq_encoder_out])\n",
    "seq2seq_Model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n",
    "seq2seq_Model.compile(optimizer=optimizers.Nadam(lr=0.001), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Examine Model Architecture Summary **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder-Input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Word-Embedding (Embeddi (None, None, 300)    1253400     Decoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Input (InputLayer)      (None, 70)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Batchnorm-1 (BatchNorma (None, None, 300)    1200        Decoder-Word-Embedding[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Model (Model)           (None, 300)          2942700     Encoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-GRU (GRU)               [(None, None, 300),  540900      Decoder-Batchnorm-1[0][0]        \n",
      "                                                                 Encoder-Model[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Batchnorm-2 (BatchNorma (None, None, 300)    1200        Decoder-GRU[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Final-Output-Dense (Dense)      (None, None, 4178)   1257578     Decoder-Batchnorm-2[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 5,996,978\n",
      "Trainable params: 5,995,178\n",
      "Non-trainable params: 1,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-99ecfa815c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mseq2seq_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mviz_model_architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mseq2seq_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mviz_model_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq_Model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/git_examples/github_issue_summarization/notebooks/seq2seq_utils.py\u001b[0m in \u001b[0;36mviz_model_architecture\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mviz_model_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0;34m\"\"\"Visualize model architecture in Jupyter notebook.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     32\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from seq2seq_utils import viz_model_architecture\n",
    "seq2seq_Model.summary()\n",
    "viz_model_architecture(seq2seq_Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "script_name_base = 'tutorial_seq2seq'\n",
    "csv_logger = CSVLogger('{:}.log'.format(script_name_base))\n",
    "model_checkpoint = ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),\n",
    "                                   save_best_only=True)\n",
    "\n",
    "batch_size = 1200\n",
    "epochs = 7\n",
    "history = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.12, callbacks=[csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "seq2seq_Model.save('seq2seq_model_tutorial.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See Example Results On Holdout Set\n",
    "\n",
    "It is useful to see examples of real predictions on a holdout set to get a sense of the performance of the model.  We will also evaluate the model numerically in a following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import dill as dpickle\n",
    "body_pp_file = \"/home/jovyan/work/model/v20180426/body_pp.dpkl\"\n",
    "\n",
    "with open(body_pp_file, 'rb') as body_file:\n",
    "  body_pp = dpickle.load(body_file)\n",
    "    \n",
    "title_pp_file = \"/home/jovyan/work/model/v20180426/title_pp.dpkl\"\n",
    "with open(title_pp_file, 'rb') as title_file:\n",
    "  title_pp = dpickle.load(title_file)\n",
    "      \n",
    "model_file = \"/home/jovyan/work/model/v20180426/seq2seq_model_tutorial.h5\"\n",
    "seq2seq_Model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from seq2seq_utils import Seq2Seq_Inference\n",
    "seq2seq_inf = Seq2Seq_Inference(encoder_preprocessor=body_pp,\n",
    "                                 decoder_preprocessor=title_pp,\n",
    "                                 seq2seq_model=seq2seq_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this method displays the predictions on random rows of the holdout set\n",
    "seq2seq_inf.demo_model_predictions(n=50, issue_df=testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model: BLEU Score\n",
    "\n",
    "For machine-translation tasks such as this one, it is common to measure the accuracy of results using the [BLEU Score](https://en.wikipedia.org/wiki/BLEU).  The convenience function illustrated below uses [NLTK's corpus_bleu](https://www.nltk.org/api/nltk.translate.html#nltk.translate.bleu_score.corpus_bleu).  The output of the below convenience function is an Average of BlEU-1, BLEU-2, BLEU-3 and BLEU-4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convenience function that generates predictions on holdout set and calculates BLEU Score\n",
    "\n",
    "bleu_score = seq2seq_inf.evaluate_model(holdout_bodies=testdf.body.tolist(), \n",
    "                                        holdout_titles=testdf.issue_title.tolist(), \n",
    "                                        max_len_title=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'BLEU Score (avg of BLUE 1-4) on Holdout Set: {bleu_score * 100}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "263px",
    "width": "352px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
